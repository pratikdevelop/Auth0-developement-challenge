{"file_contents":{"main.py":{"content":"from openai import OpenAI\n\nclient = OpenAI(\n    base_url=\"https://integrate.api.nvidia.com/v1\",\n    api_key=\n    \"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\")\n\nprompt = input(\"enter your prompt\")\n\nif prompt:\n    completion = client.chat.completions.create(\n        model=\"meta/llama-3.2-3b-instruct\",\n        messages=[{\n            \"role\": \"user\",\n            \"content\": prompt\n        }],\n        temperature=1.0,\n        top_p=1,\n        max_tokens=3000,\n        stream=True)\n\n    for chunk in completion:\n        if chunk.choices[0].delta.content is not None:\n            print(chunk.choices[0].delta.content, end=\"\")\n    print('/n')\nelse:\n    print('prmpt is required')\n","size_bytes":703},"pyproject.toml":{"content":"[project]\nname = \"python-template\"\nversion = \"0.1.0\"\ndescription = \"\"\nauthors = [\"Your Name <you@example.com>\"]\nrequires-python = \">=3.11\"\ndependencies = [\n    \"openai>=1.93.3\",\n]\n","size_bytes":180}},"version":2}